ğŸ– Hand Gesture Recognition using CNN

ğŸ“Œ Overview

This project focuses on Hand Gesture Recognition using a Convolutional Neural Network (CNN) trained on a 2GB dataset of various hand gesture images. The trained model is then used for real-time gesture recognition via an external camera. The project is implemented in Python using Google Colab for training due to computational constraints.

ğŸš€ Features
âœ… Preprocessing of hand gesture images
âœ… CNN model implementation for classification
âœ… Training on a large dataset (2GB)
âœ… Real-time gesture recognition using an external camera
âœ… Model evaluation with accuracy and loss metrics
âœ… Visualization of training progress

ğŸ›  Technologies Used
Python ğŸ

TensorFlow/Keras ğŸ”¥

OpenCV ğŸ¥

NumPy & Pandas ğŸ“Š

Matplotlib & Seaborn ğŸ“ˆ

Google Colab ğŸ’»

ğŸ“‚ Dataset
The dataset consists of various hand gesture images, which are preprocessed before training. It includes resizing, normalization, and data augmentation to enhance model generalization.

ğŸ— Model Architecture
The CNN model comprises:
ğŸ”¹ Convolutional Layers â€“ Feature extraction from images
ğŸ”¹ Pooling Layers â€“ Reducing dimensionality and overfitting
ğŸ”¹ Fully Connected Layers â€“ Classification of gestures
ğŸ”¹ Softmax Activation â€“ Multi-class classification

ğŸ”¬ Training & Evaluation
The model is trained using Stochastic Gradient Descent (SGD) with categorical cross-entropy loss.

Loss and accuracy are monitored during training.

Results are visualized using matplotlib.

A confusion matrix is used to analyze performance.

ğŸ¥ Real-time Gesture Recognition
Once trained, the model is deployed to recognize gestures in real time using OpenCV and an external camera.

ğŸ“Š Results
The model achieves high accuracy in classifying gestures, making it suitable for applications in sign language interpretation, gaming, and human-computer interaction.
